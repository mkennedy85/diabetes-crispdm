{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Repo Setup (Colab)\n",
    "# This cell ensures a fresh copy of the repo is available in Colab every time.\n",
    "# It removes any old copy, clones the latest repo, and sets up the environment.\n",
    "\n",
    "import os, sys\n",
    "\n",
    "REPO_URL = \"https://github.com/mkennedy85/diabetes-crispdm.git\"\n",
    "REPO_DIR = \"diabetes-crispdm\"\n",
    "\n",
    "# Always start fresh\n",
    "!rm -rf $REPO_DIR\n",
    "print(\"Cloning repo from:\", REPO_URL)\n",
    "!git clone $REPO_URL\n",
    "\n",
    "# Change working directory to repo root\n",
    "%cd $REPO_DIR\n",
    "\n",
    "# Ensure Python can import the local package\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "print(\"âœ… Repo ready at:\", os.getcwd())\n",
    "print(\"Contents:\", os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¤ Upload Dataset into Colab\n",
    "# Run this cell to upload your CSV (e.g. diabetes_binary_health_indicators_BRFSS2015.csv)\n",
    "# It will be placed into the \"data/\" folder.\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "uploaded = files.upload()\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    os.rename(fn, f\"data/{fn}\")\n",
    "\n",
    "print(\"Available files in data/:\", os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to uploaded dataset\n",
    "DATA_PATH = \"data/diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
    "# Or use multiclass dataset if uploaded:\n",
    "# DATA_PATH = \"data/diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f3aa94",
   "metadata": {},
   "source": [
    "\n",
    "**Author:** Michael Kennedy  \n",
    "**Run date:** 2025-09-14T04:04:01.008526Z\n",
    "\n",
    "> This notebook follows CRISP-DM: Business â†’ Data Understanding â†’ Preparation â†’ Modeling â†’ Evaluation â†’ Deployment.\n",
    "\n",
    "**Constraints:** 8 GB RAM; pure NumPy/Pandas/Scikit + a compact PyTorch MLP for deep learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387502fa",
   "metadata": {},
   "source": [
    "## Phase 2: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b784c1",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6dedb2",
   "metadata": {},
   "source": [
    "![Class Distribution](../reports/figures/class_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ffeeab",
   "metadata": {},
   "source": [
    "### Top-variance correlation heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd81fb",
   "metadata": {},
   "source": [
    "![Correlation Heatmap](../reports/figures/corr_heatmap_top20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc385ca",
   "metadata": {},
   "source": [
    "### Univariate distributions of top features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441f18f",
   "metadata": {},
   "source": [
    "![Univariate Top 6](../reports/figures/univariate_top6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e610c",
   "metadata": {},
   "source": [
    "### Simple importance proxy (|corr| or variance ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b57798",
   "metadata": {},
   "source": [
    "![Feature proxy](../reports/figures/feature_importance_proxy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dec0b4",
   "metadata": {},
   "source": [
    "## Phase 3: Data Preparation & Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This section is handled by the training scripts; refer to btds/train.py for deterministic splits and scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20fb8b",
   "metadata": {},
   "source": [
    "## Phase 4: Baseline Modeling (Scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fac54",
   "metadata": {},
   "source": [
    "![Confusion Matrix](../reports/figures/cm_logreg_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067cb16a",
   "metadata": {},
   "source": [
    "![ROC Curve](../reports/figures/roc_logreg_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d72724",
   "metadata": {},
   "source": [
    "![PR Curve](../reports/figures/pr_logreg_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd248a",
   "metadata": {},
   "source": [
    "![Calibration](../reports/figures/calibration_logreg_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54aa5bf",
   "metadata": {},
   "source": [
    "![Permutation Importance](../reports/figures/permutation_importance_val.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66121d69",
   "metadata": {},
   "source": [
    "## Phase 4: Deep Learning Baseline (PyTorch MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce18f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run from terminal: python -m btds.train --data_path data/your_file.csv --out_dir reports\n",
    "# The notebook focuses on EDA visuals while the training script saves metrics and model weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3ca27",
   "metadata": {},
   "source": [
    "## Phase 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, os, pprint\n",
    "with open(\"reports/baseline_logreg_metrics.json\") as f:\n",
    "    metrics = json.load(f)\n",
    "pprint.pp(metrics)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
